# SAM2 for Surgical Workflow Analysis
## Project Overview
"We are trying to get SAM2 to help with the 'Surgical Workflow Analysis' problem."
# Installing SAM2
Installation
#### SAM 2 needs to be installed first before use.
#### The code requires python>=3.10, as well as torch>=2.3.1 and torchvision>=0.18.1. 
#### Please follow the instructions here to install both PyTorch and TorchVision dependencies. You can install SAM 2 on a GPU machine using:

git clone https://github.com/facebookresearch/segment-anything-2.git
cd segment-anything-2 & pip install -e .

#### To use the SAM 2 predictor and run the example notebooks, jupyter and matplotlib are required and can be installed by:
  pip install -e ".[demo]"
#### Download Checkpoints
##### First, we need to download a model checkpoint. All the model checkpoints can be downloaded by running:
#### cd checkpoints && \
#### ./download_ckpts.sh && \
#### cd ..
### or individually from:
### https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt


## Implementation Details

- **Video Processing**: In the `SAM_Video.ipynb` notebook, we employed YOLO for detecting polyps in the first frame. 
- ####Download the fine-tuned Yolo Version on the link below
- [Download YOLOv8 Weights](https://drive.google.com/file/d/1eq09PoATfvMOf6fPzsnQzQsve1OebJ02/view?usp=drive_link)

- The bounding boxes generated by YOLO serve as prompts for SAM2 to analyze the workflow effectively.
  
- **Frame Extraction**: Within the same notebook, there is a section labeled **"# convert Video to Frame"** where we modified the extraction rate to obtain **5 frames per second** instead of the default **25 frames**.


